{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e0e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Circadian Semantic Exploration Analysis\n",
    "# Global vs User-level Entropy\n",
    "# ============================================================\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca8cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\github\\circadian_social_network\\transformers\\src\\transformers\\tokenization_utils_base.py:1614: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Processing month 01 ==========\n",
      "Posts after cleaning: 366778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366778/366778 [00:08<00:00, 42311.16it/s]\n",
      "Embedding text: 100%|██████████| 42/42 [29:15<00:00, 41.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2349/2349 [03:03<00:00, 12.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 01\n",
      "\n",
      "========== Processing month 02 ==========\n",
      "Posts after cleaning: 345913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345913/345913 [00:07<00:00, 45241.26it/s]\n",
      "Embedding text: 100%|██████████| 39/39 [29:12<00:00, 44.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2340/2340 [02:59<00:00, 13.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 02\n",
      "\n",
      "========== Processing month 03 ==========\n",
      "Posts after cleaning: 399769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399769/399769 [00:12<00:00, 32599.31it/s]\n",
      "Embedding text: 100%|██████████| 45/45 [33:41<00:00, 44.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2414/2414 [03:07<00:00, 12.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 03\n",
      "\n",
      "========== Processing month 04 ==========\n",
      "Posts after cleaning: 395468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395468/395468 [00:10<00:00, 36462.57it/s]\n",
      "Embedding text: 100%|██████████| 46/46 [32:50<00:00, 42.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2382/2382 [03:08<00:00, 12.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 04\n",
      "\n",
      "========== Processing month 05 ==========\n",
      "Posts after cleaning: 408093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408093/408093 [00:11<00:00, 36837.91it/s]\n",
      "Embedding text: 100%|██████████| 47/47 [32:05<00:00, 40.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2383/2383 [03:13<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 05\n",
      "\n",
      "========== Processing month 06 ==========\n",
      "Posts after cleaning: 384209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384209/384209 [00:10<00:00, 36343.46it/s]\n",
      "Embedding text: 100%|██████████| 44/44 [29:15<00:00, 39.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2439/2439 [03:12<00:00, 12.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 06\n",
      "\n",
      "========== Processing month 07 ==========\n",
      "Posts after cleaning: 408035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408035/408035 [00:11<00:00, 36976.32it/s]\n",
      "Embedding text: 100%|██████████| 47/47 [30:57<00:00, 39.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2450/2450 [03:24<00:00, 12.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 07\n",
      "\n",
      "========== Processing month 08 ==========\n",
      "Posts after cleaning: 419450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419450/419450 [00:11<00:00, 36854.15it/s]\n",
      "Embedding text: 100%|██████████| 48/48 [31:36<00:00, 39.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2487/2487 [03:42<00:00, 11.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 08\n",
      "\n",
      "========== Processing month 09 ==========\n",
      "Posts after cleaning: 415302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415302/415302 [00:11<00:00, 35646.42it/s]\n",
      "Embedding text: 100%|██████████| 47/47 [30:39<00:00, 39.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2443/2443 [03:24<00:00, 11.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 09\n",
      "\n",
      "========== Processing month 10 ==========\n",
      "Posts after cleaning: 450065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450065/450065 [00:12<00:00, 37155.49it/s]\n",
      "Embedding text: 100%|██████████| 52/52 [33:23<00:00, 38.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2498/2498 [03:29<00:00, 11.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 10\n",
      "\n",
      "========== Processing month 11 ==========\n",
      "Posts after cleaning: 407896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407896/407896 [00:11<00:00, 35729.28it/s]\n",
      "Embedding text: 100%|██████████| 47/47 [31:39<00:00, 40.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2466/2466 [03:23<00:00, 12.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 11\n",
      "\n",
      "========== Processing month 12 ==========\n",
      "Posts after cleaning: 398235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398235/398235 [00:10<00:00, 36209.61it/s]\n",
      "Embedding text: 100%|██████████| 46/46 [31:45<00:00, 41.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entropy per country × LOCAL hour: 100%|██████████| 2515/2515 [03:21<00:00, 12.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LOCAL-time entropy CSVs for month 12\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0. Load timezone lookup ONCE\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "tz_lookup = pd.read_csv(\"city_country_timezone_lookup.csv\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DST-aware UTC → local hour\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def utc_to_local_hour_dst(utc_ts, month, timezone_str):\n",
    "    if pd.isna(utc_ts) or pd.isna(timezone_str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        tz = pytz.timezone(timezone_str)\n",
    "\n",
    "        # stabilize DST using mid-month date\n",
    "        utc_dt = utc_ts.replace(\n",
    "            year=2024,\n",
    "            month=int(month),\n",
    "            day=15\n",
    "        )\n",
    "\n",
    "        return utc_dt.astimezone(tz).hour\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Entropy functions\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def individual_entropy(X, k=10):\n",
    "    X = X.astype(\"float32\")\n",
    "    index = faiss.IndexFlatL2(X.shape[1])\n",
    "    index.add(X)\n",
    "    D, _ = index.search(X, k + 1)\n",
    "    r_k = D[:, -1]\n",
    "    return np.log(r_k + 1e-10)\n",
    "\n",
    "\n",
    "def global_entropy(X, eps=1e-6):\n",
    "    X = X.astype(\"float64\")\n",
    "    d = X.shape[1]\n",
    "\n",
    "    cov = np.cov(X, rowvar=False)\n",
    "    cov += eps * np.eye(d)\n",
    "\n",
    "    sign, logdet = np.linalg.slogdet(cov)\n",
    "    if sign <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    return 0.5 * (d * np.log(2 * np.pi * np.e) + logdet)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Sentence embedding model\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "batch_size = 8192\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Monthly processing loop\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "for month in [\"01\",\"02\", \"03\",\"04\", \"05\", \"06\",\n",
    "              \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]:\n",
    "\n",
    "    print(f\"\\n========== Processing month {month} ==========\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1. Load & clean data\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    chunk_paths = sorted(\n",
    "        glob.glob(f\"./2024/RS_2024-{month}/chunk_*.csv\")\n",
    "    )\n",
    "\n",
    "    dfs = [pd.read_csv(p) for p in chunk_paths]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    del dfs\n",
    "\n",
    "    df[\"selftext\"] = df[\"selftext\"].fillna(\"\")\n",
    "    df[\"title\"] = df[\"title\"].fillna(\"\")\n",
    "    df[\"text\"] = df[\"title\"] + \". \" + df[\"selftext\"]\n",
    "\n",
    "    df = df[~df[\"text\"].str.strip().isin([\"\", \"[removed]\", \"[deleted]\"])]\n",
    "    df = df[~df[\"author\"].str.strip().isin([\"\", \"[removed]\", \"[deleted]\"])]\n",
    "\n",
    "    df[\"created_utc\"] = pd.to_datetime(\n",
    "        df[\"created_utc\"], utc=True, errors=\"coerce\"\n",
    "    )\n",
    "    df = df.dropna(subset=[\"created_utc\"])\n",
    "\n",
    "    # Preserve UTC metadata ONLY\n",
    "    df[\"utc_hour\"] = df[\"created_utc\"].dt.hour\n",
    "    df[\"month\"] = int(month)\n",
    "\n",
    "    print(f\"Posts after cleaning: {len(df)}\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2. Merge timezone lookup\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    df = df.merge(\n",
    "        tz_lookup,\n",
    "        on=[\"loc_city\", \"loc_country\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3. Compute LOCAL HOUR (DST-aware)\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    df[\"local_hour\"] = df.progress_apply(\n",
    "        lambda r: utc_to_local_hour_dst(\n",
    "            r[\"created_utc\"],\n",
    "            r[\"month\"],\n",
    "            r[\"timezone\"]\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df = df.dropna(subset=[\"local_hour\"])\n",
    "    df[\"local_hour\"] = df[\"local_hour\"].astype(int)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4. Embed text\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(0, len(df), batch_size),\n",
    "        desc=\"Embedding text\"\n",
    "    ):\n",
    "        batch = df[\"text\"].iloc[i:i + batch_size].tolist()\n",
    "        emb = model.encode(\n",
    "            batch,\n",
    "            normalize_embeddings=True,\n",
    "            device=\"cuda\"\n",
    "        )\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    df[\"embedding\"] = np.vstack(embeddings).tolist()\n",
    "    print(\"Embedding complete.\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 5. ENTROPY BY *LOCAL HOUR* (ONLY)\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    individual_results = []\n",
    "    global_results = []\n",
    "\n",
    "    for (country, h), sub in tqdm(\n",
    "        df.groupby([\"loc_country\", \"local_hour\"]),\n",
    "        desc=\"Entropy per country × LOCAL hour\"\n",
    "    ):\n",
    "        if len(sub) < 10:   # avoid unstable covariance\n",
    "            continue\n",
    "\n",
    "        X = np.vstack(sub[\"embedding\"].values)\n",
    "\n",
    "        # --- 1. Global entropy\n",
    "        glob_ent = global_entropy(X)\n",
    "        global_results.append({\n",
    "            \"month\": month,\n",
    "            \"loc_country\": country,\n",
    "            \"local_hour\": h,\n",
    "            \"global_entropy\": glob_ent,\n",
    "            \"n_posts\": len(sub)\n",
    "        })\n",
    "\n",
    "        # --- 2. Individual post entropy\n",
    "        ind_ent = individual_entropy(X, k=10)  \n",
    "\n",
    "        # Save individual entropy\n",
    "        for idx, e in zip(sub.index, ind_ent):\n",
    "            individual_results.append({\n",
    "                \"post_idx\": idx,\n",
    "                \"author\": sub.loc[idx, \"author\"],\n",
    "                \"local_hour\": sub.loc[idx, \"local_hour\"],\n",
    "                \"created_utc\": sub.loc[idx, \"created_utc\"],\n",
    "                \"utc_hour\": sub.loc[idx, \"utc_hour\"],\n",
    "                \"month\": month,\n",
    "                \"individual_entropy\": e,\n",
    "                \"loc_city\": sub.loc[idx, \"loc_city\"],\n",
    "                \"loc_country\": sub.loc[idx, \"loc_country\"],\n",
    "                \"timezone\": sub.loc[idx, \"timezone\"],\n",
    "                \"sentiment_compound\": sub.loc[idx, \"sentiment_compound\"]\n",
    "                if \"sentiment_compound\" in sub.columns else None\n",
    "            })\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6. Save CSVs\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    pd.DataFrame(individual_results).to_csv(\n",
    "        f\"individual_post_entropy_LOCAL_DST_{month}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(global_results).to_csv(\n",
    "        f\"global_entropy_LOCAL_hour_DST_{month}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"Saved LOCAL-time entropy CSVs for month {month}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssq_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
